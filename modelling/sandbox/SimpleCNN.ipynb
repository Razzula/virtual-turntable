{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision.datasets import ImageFolder\n",
    "from torch.utils.data import DataLoader\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## I. Data Handling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset ImageFolder\n",
      "    Number of datapoints: 15\n",
      "    Root location: d:\\Programming\\UoM\\virtual-turntable\\modelling\\sandbox\\..\\data\\art\n",
      "    StandardTransform\n",
      "Transform: Compose(\n",
      "               Resize(size=(224, 224), interpolation=bilinear, max_size=None, antialias=True)\n",
      "               ToTensor()\n",
      "               Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
      "           )\n",
      "['AbbeyRoad_TheBeatles', 'InRainbows_Radiohead', \"JeffWayne'sMusicalVersionofTheWaroftheWorlds_JeffWayne\", 'KidA_Radiohead', 'OKComputer_Radiohead', 'Revolver_TheBeatles', \"Sgt.Pepper'sLonelyHeartsClubBand_TheBeatles\", 'TheDarkSideOfTheMoon_PinkFloyd', 'TheRiseAndFallOfZiggyStardustAndTheSpidersFromMars_DavidBowie', 'TheVelvetUnderground&Nico_TheVelvetUnderground&Nico', 'WishYouWereHere_PinkFloyd']\n"
     ]
    }
   ],
   "source": [
    "transform = transforms.Compose([\n",
    "    # ensure images are of uniform size\n",
    "    # this is necessary for the neural network to be able to process the images\n",
    "    transforms.Resize((224, 224)),\n",
    "\n",
    "    # ensure the end result is a tensor\n",
    "    # this converts the image from [0,255] to [0,1]\n",
    "    # making it compatible with the neural network\n",
    "    transforms.ToTensor(),\n",
    "\n",
    "    # normalise the data\n",
    "    transforms.Normalize(\n",
    "        # this is the mean and standard deviation of the ImageNet dataset\n",
    "        # the pixel value, for each channel, is subtracted by the mean and divided by the standard deviation\n",
    "        # this should shift the pixel values to be centred around zero (mean: 0, std: 1)\n",
    "        # this allows faster and more stable convergence during optimisation\n",
    "        mean=[0.485, 0.456, 0.406],\n",
    "        std=[0.229, 0.224, 0.225]\n",
    "    )\n",
    "])\n",
    "\n",
    "# LOAD DATASET\n",
    "rootDir = globals()['_dh'][0] # os.path.dirname(os.path.abspath(__file__))\n",
    "dataDir = os.path.join(rootDir, '..', 'data', 'art')\n",
    "dataSet = ImageFolder(root=dataDir, transform=transform) # load each subdirectory as a class\n",
    "\n",
    "print(dataSet)\n",
    "print(dataSet.classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: Data augmentation should be done in the future, to create a more robust dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SPLIT DATA\n",
    "trainLoader = DataLoader(dataSet, batch_size=8, shuffle=True)\n",
    "validationLoader = DataLoader(dataSet, batch_size=8, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## II. Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleCNN(nn.Module):\n",
    "    \"\"\"\n",
    "    This is a simple convolutional neural network, for POC.\n",
    "    It has two convolutional layers and two fully connected layers (see below).\n",
    "    It effectively learns the 'ID' of the image (albumName_artistName).\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, numClasses):\n",
    "        super(SimpleCNN, self).__init__()\n",
    "\n",
    "        # This is the architecture of the neural network.\n",
    "        # It is composed of two convolutional layers and two fully connected layers.\n",
    "        # conv1 -> pool -> conv2 -> pool -> fc1 -> fc2\n",
    "\n",
    "        # CONVOLUTIONAL LAYER 1\n",
    "        self.conv1 = nn.Conv2d(\n",
    "            3, # 3 channels (RBG)\n",
    "            32, # 32 output filters (feature maps)\n",
    "            kernel_size=3, # each filter will scan 3x3 patches of the image\n",
    "            stride=1, # each filter will move 1 pixel at a time\n",
    "            padding=1 # the input is padded, to esnure the output is the same size as the input\n",
    "        )\n",
    "\n",
    "        # MAX-POOLING LAYER\n",
    "        # reduces spatial dimensions of the input feature maps\n",
    "        # this reduces the number of parameters and computations in the network\n",
    "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2, padding=0)\n",
    "\n",
    "        # CONVOLUTIONAL LAYER 2\n",
    "        # the 32 feature maps are now fed into a second layer, resulting in 64 output filters\n",
    "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1)\n",
    "\n",
    "        # FULLY CONNECTED LAYER 1\n",
    "        self.fc1 = nn.Linear(\n",
    "            64 * 56 * 56, # 64 feature maps, each 56x56 pixels\n",
    "            128 # 128 output neurons\n",
    "        )\n",
    "\n",
    "        # FULLY CONNECTED LAYER 2\n",
    "        # this layer outputs logits (raw scores) for each class\n",
    "        self.fc2 = nn.Linear(128, numClasses)\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"_summary_\n",
    "\n",
    "        Args:\n",
    "            x (_type_): _description_\n",
    "\n",
    "        Returns:\n",
    "            _type_: _description_\n",
    "        \"\"\"\n",
    "\n",
    "        # pool the first convolutional layer\n",
    "        # the size of the feature maps are halved\n",
    "        x = self.pool(\n",
    "            # apply the ReLU activation function\n",
    "            # this introduces non-linearity to the model\n",
    "            torch.relu(\n",
    "                # apply the first convolutional layer\n",
    "                # the 32 filters are applied to the input image\n",
    "                self.conv1(x)\n",
    "            )\n",
    "        )\n",
    "\n",
    "        # pool the second convolutional layer\n",
    "        x = self.pool(torch.relu(self.conv2(x)))\n",
    "\n",
    "        # flatten the feature maps\n",
    "        x = x.view(-1, 64 * 56 * 56)\n",
    "\n",
    "        # fully-connected layers\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = self.fc2(x) # no activation function, as this is handled by the loss function\n",
    "\n",
    "        return x\n",
    "\n",
    "numClasses = len(dataSet.classes)\n",
    "model = SimpleCNN(numClasses=numClasses)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## III. Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LOSS FUNCTION\n",
    "# used to compute the error between the model's predictions and the true labels\n",
    "critereon = nn.CrossEntropyLoss()\n",
    "\n",
    "# OPTIMISER\n",
    "# updates the model's weights, based on gradients\n",
    "optimiser = optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(Epoch 1) Loss: 17.850367426872253\t Accuracy: 0.13333333333333333\n",
      "(Epoch 2) Loss: 3.849959373474121\t Accuracy: 0.3333333333333333\n",
      "(Epoch 3) Loss: 0.41283509880304337\t Accuracy: 0.7333333333333333\n",
      "(Epoch 4) Loss: 0.024807718116790056\t Accuracy: 1.0\n",
      "(Epoch 5) Loss: 0.02074203360825777\t Accuracy: 1.0\n"
     ]
    }
   ],
   "source": [
    "def train(model, trainLoader, critereon, optimiser, epochs=5):\n",
    "    \"\"\"_summary_\n",
    "\n",
    "    Args:\n",
    "        model (_type_): _description_\n",
    "        trainLoader (_type_): _description_\n",
    "        critereon (_type_): _description_\n",
    "        optimiser (_type_): _description_\n",
    "        epochs (int, optional): _description_. Defaults to 5.\n",
    "    \"\"\"\n",
    "\n",
    "    # EPOCH LOOP\n",
    "    # an epoch is a complete pass through the dataset\n",
    "    # we do this several times, to allow the model to learn\n",
    "    for epoch in range(epochs):\n",
    "\n",
    "        model.train() # set the model to training mode (this is necessary for dropout and batch normalisation)\n",
    "\n",
    "        # initialsie some statistic-trackers\n",
    "        runningLoss = 0.0 # cumulative loss\n",
    "        correct, total = 0, 0 # correct predictions, total predictions\n",
    "\n",
    "        # TRAINING LOOP\n",
    "        for images, labels in trainLoader:\n",
    "            optimiser.zero_grad() # prevent accumulated gradients from previous iterations overflowing\n",
    "\n",
    "            # FORWARD PASS\n",
    "            # pass the images into the model, producing a prediction\n",
    "            outputs = model(images)\n",
    "\n",
    "            # COMPUTE LOSS\n",
    "            # compare the model's predictions to the true labels\n",
    "            loss = critereon(outputs, labels)\n",
    "\n",
    "            # BACKPROPAGATION\n",
    "            # compute the gradients of the loss, with respect to the model's parameters/weights\n",
    "            loss.backward()\n",
    "            # and update the model's weights accordingly\n",
    "            optimiser.step()\n",
    "\n",
    "            # track stats\n",
    "            runningLoss += loss.item()\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "        print(f'(Epoch {epoch+1}) Loss: {runningLoss/len(trainLoader)}\\t Accuracy: {correct/total}')\n",
    "\n",
    "train(model, trainLoader, critereon, optimiser, epochs=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## IV. Validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Seen data (hopefully, expacted)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted: JeffWayne'sMusicalVersionofTheWaroftheWorlds_JeffWayne (0.999643087387085)\n"
     ]
    }
   ],
   "source": [
    "testImage = Image.open(os.path.join(rootDir, '..', 'data', 'misc', \"JeffWayne'sMusicalVersionofTheWaroftheWorlds_JeffWayne(2).png\"))\n",
    "testImage = transform(testImage)\n",
    "testImage = testImage.unsqueeze(0) # add batch dimension, as model expects it\n",
    "\n",
    "model.eval()\n",
    "\n",
    "with torch.no_grad():\n",
    "    outputs = model(testImage)\n",
    "\n",
    "    probabilities = torch.nn.functional.softmax(outputs, dim=1)\n",
    "    predictedProb, predictedClass = torch.max(probabilities, 1)\n",
    "\n",
    "    print(f'Predicted: {dataSet.classes[predictedClass.item()]} ({predictedProb.item()})')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unseen data (the model is not expected to perform well)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted: OKComputer_Radiohead (0.6633164286613464)\n"
     ]
    }
   ],
   "source": [
    "testImage = Image.open(os.path.join(rootDir, '..', 'data', 'misc', 'ABBA_ABBA.png'))\n",
    "testImage = transform(testImage).unsqueeze(0)\n",
    "\n",
    "model.eval()\n",
    "\n",
    "with torch.no_grad():\n",
    "    outputs = model(testImage)\n",
    "\n",
    "    probabilities = torch.nn.functional.softmax(outputs, dim=1)\n",
    "    predictedProb, predictedClass = torch.max(probabilities, 1)\n",
    "\n",
    "    print(f'Predicted: {dataSet.classes[predictedClass.item()]} ({predictedProb.item()})')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: the sum of the probabilities will be 1. Therefore, with a small datatset, the model may be confidently wrong (i.e. a high probability for the wrong class), as this is moreso a measure of 'how confident I am it is this, compared to the other options', as opposed to 'how confident I am that it is this, and not anything else'. This is important to note when interpreting the results (we should have a high standard for confidence). However, as the dataset grows, the liklihood of any one class being highly-favoured, when the true result lies outside of the trained classes, should decrease."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "vtt-modelling",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
